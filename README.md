# DEAP LEARING

## Install libs
```python3 -m venv venv```

```pip install -r requirements.txt```

##  Оглавление

## 1. Введение в глубокое обучение: зачем его изучать
##### Добро пожаловать в «Грокаем глубокое обучение»!
##### Почему вам стоит изучать глубокое обучение
##### Этому трудно учиться?
##### Почему вы должны прочитать эту книгу
##### Что нужно для начала
##### Возможно, вам потребуется знание Python 
##### Итоги

## 2. Основные понятия: как учатся машины?
##### Что такое глубокое обучение?
##### Что такое машинное обучение?
##### Машинное обучение с учителем
##### Машинное обучение без учителя
##### Параметрическое и непараметрическое обучение
##### Параметрическое обучение с учителем
##### Параметрическое обучение без учителя
##### Непараметрическое обучение
##### Итог

## 3. Введение в нейронное прогнозирование: прямое распространение
##### Шаг 1: прогнозирование
##### Простая нейронная сеть, делающая прогноз
##### Что такое нейронная сеть?
##### Что делает эта нейронная сеть?
##### Прогнозирование с несколькими входами
##### Несколько входов: что делает эта нейронная сеть?
##### Несколько входов: полный выполняемый код
##### Прогнозирование с несколькими выходами
##### Прогнозирование с несколькими входами и выходами
##### Несколько входов и выходов: как это работает?
##### Прогнозирование на основе прогнозов
##### Короткий пример использования NumPy
##### Итоги

## 4. Введение в нейронное обучение: градиентный спуск
##### Предсказание, сравнение и обучение
##### Сравнение Обучение
##### Сравнение: способны ли нейронные сети делать точные прогнозы?
##### Зачем измерять ошибку?
##### Как выглядит простейшая форма нейронного обучения?
##### Обучение методом «холодно/горячо»
##### Особенности обучения методом «холодно/горячо»
##### Вычисление направления и величины из ошибки
##### Одна итерация градиентного спуска
##### Обучение просто уменьшает ошибку
##### Рассмотрим несколько циклов обучения
##### Как это работает? Что такое weight_delta на самом деле?
##### Узкий взгляд на одно понятие
##### Коробка со стержнями
##### Производные: второй пример
##### Что действительно необходимо знать
##### Что знать необязательно
##### Как использовать производные для обучения
##### Выглядит знакомо?
##### Ломаем градиентный спуск
##### Визуальное представление избыточной коррекции
##### Расхождение
##### Знакомьтесь: альфа-коэффициент
##### Альфа-коэффициент в коде
##### Запоминание

## 5. Корректировка сразу нескольких весов: обобщение градиентного спуска
##### Обучение методом градиентного спуска с несколькими входами
##### Градиентный спуск с несколькими входами, описание
##### Рассмотрим несколько шагов обучения
##### Замораживание одного веса: для чего?
##### Обучение методом градиентного спуска с несколькими выходами
##### Обучение методом градиентного спуска с несколькими входами и выходами
##### Чему обучаются эти веса?
##### Визуализация значений весов
##### Визуализация скалярных произведений (сумм весов)
##### Итоги

## 6. Создание первой глубокой нейронной сети: введение в обратное распространение
##### Задача о светофор
##### Подготовка данных
##### Матрицы и матричные отношения
##### Создание матриц в Python
##### Создание нейронной сети
##### Обучение на полном наборе данных
##### Полный, пакетный и стохастический градиентный спуск
##### Нейронные сети изучают корреляцию
##### Повышающее и понижающее давление
##### Пограничный случай: переобучение
##### Пограничный случай: конфликт давлений
##### Определение косвенной корреляции
##### Создание корреляции
##### Объединение нейронных сетей в стек: обзор
##### Обратное распространение: определение причин ошибок на расстоянии
##### Обратное распространение: как это работает?
##### Линейность и нелинейность
##### Почему составная нейронная сеть не работает
##### Тайна эпизодической корреляции
##### Короткий перерыв
##### Ваша первая глубокая нейронная сеть
##### Обратное распространение в коде
##### Одна итерация обратного распространения
##### Объединяем все вместе
##### Почему глубокие сети важны для нас?

## 7. Обратное распространение: определение причин ошибок на расстоянии
##### Обратное распространение: как это работает?
##### Линейность и нелинейность
##### Почему составная нейронная сеть не работает
##### Тайна эпизодической корреляции
##### Короткий перерыв
##### Ваша первая глубокая нейронная сеть
##### Обратное распространение в коде
##### Одна итерация обратного распространения
##### Объединяем все вместе
##### Почему глубокие сети важны для нас?
##### Как изобразить нейронную сеть: в голове и на бумаге
##### Время упрощать
##### Обобщение корреляции
##### Прежняя усложненная визуализация
##### Упрощенная визуализация
##### Еще более упрощенная визуализация
##### Посмотрим, как эта сеть получает прогноз
##### Визуализация с использованием букв вместо картинок
##### Связывание переменных
##### Сравнение разных способов визуализации
##### Важность инструментов визуализации

## 8. Усиление сигнала и игнорирование шума: введение в регуляризацию и группировку
##### Трехслойная сеть для классификации набора данных MNIST
##### Это было просто
##### Запоминание и обобщение
##### Переобучение нейронных сетей
##### Причины переобучения
##### Простейшая регуляризация: ранняя остановка
##### Стандартный способ регуляризации: прореживание (дропаут)
##### Как работает прореживание: в работе участвуют ансамбли
##### Прореживание в коде
##### Влияние прореживания на модель MNIST
##### Пакетный градиентный спуск
##### Итоги

## 9. Моделирование случайности и нелинейности: функции активации
##### Что такое функция активации?
##### Стандартные функции активации для скрытых слоев
##### Стандартные функции активации для выходного слоя
##### Главная проблема: входные данные могут быть схожи между собой
##### Вычисление softmax
##### Инструкции по внедрению функций активации
##### Умножение разности на производную
##### Преобразование выхода в наклон (производную)
##### Усовершенствование сети MNIST

## 10. Края и углы нейронного обучения: введение в сверточные нейронные сети
##### Повторное использование весов в нескольких местах
##### Сверточный слой
##### Простая реализация в NumPy
##### Итоги

## 11. Нейронные сети, понимающие человеческий язык: король - мужчина + женщина ==?
##### Что значит понимать человеческий язык?
##### Обработка естественного языка (NLP)
##### Обработка естественного языка с учителем
##### Набор данных IMDB с обзорами фильмов
##### Выявление корреляции слов во входных данных
##### Прогнозирование обзоров фильмов
##### Введение в слой с векторным представлением
##### Интерпретация результата
##### Нейронная архитектура
##### Сравнение векторных представлений слов
##### В чем заключается смысл нейрона?
##### Подстановка пропущенных слов
##### Смысл определяется потерями
##### Король - мужчина + женщина ~= королева
##### Словесные аналогии
##### Итоги

## 12. Нейронные сети, которые пишут как Шекспир: рекуррентные слои для данных переменной длины
##### Проблема произвольной длины
##### Действительно ли сравнение имеет значение?
##### Удивительная мощь усредненных векторов слов
##### Как векторные представления хранят информацию?
##### Как нейронная сеть использует векторные представления?
##### Ограничение векторов в модели «мешок слов»
##### Объединение векторных представлений слов с использованием
##### единичной матрицы
##### Матрицы, которые ничего не меняют
##### Определение переходных матриц
##### Обучение созданию векторов предложений
##### Прямое распространение на Python
##### Как добавить сюда обратное распространение?
##### Обучим ее!
##### Подготовка
##### Прямое распространение с данными произвольной длины
##### Обратное распространение с данными произвольной длины
##### Корректировка весов с данными произвольной длины
##### Запуск и анализ результатов
##### Итоги

## 13. Введение в автоматическую оптимизацию: создание фреймворка глубокого обучения
##### Что такое фреймворк глубокого обучения?
##### Введение в тензоры
##### Введение в автоматическое вычисление градиента (autograd)
##### Контрольная точка
##### Тензоры, используемые многократно
##### Добавление поддержки тензоров многократного использования в реализацию autograd
##### Как работает сложение в обратном распространении?
##### Добавление поддержки отрицания
##### Добавление поддержки других операций
##### Использование autograd в обучении нейронной сети
##### Добавление автоматической оптимизации
##### Добавление поддержки слоев разных типов
##### Слои, содержащие другие слои
##### Слои с функцией потерь
##### Как научиться пользоваться фреймворком
##### Нелинейные слои
##### Слой с векторным представлением
##### Добавление индексирования в autograd
##### Слой с векторным представлением (повтор)
##### Слой с перекрестной энтропией
##### Рекуррентный слой
##### Итог

## 14. Обучаем сеть писать как Шекспир: долгая краткосрочная память
##### Моделирование языка символов
##### Необходимо усеченное обратное распространение
##### Усеченное обратное распространение
##### Образец вывода
##### Затухающие и взрывные градиенты
##### Упрощенный пример обратного распространения в RNN
##### Ячейки долгой краткосрочной памяти (LSTM)
##### Аналогия, помогающая понять идею вентилей LSTM
##### Слой долгой краткосрочной памяти
##### Усовершенствование модели языка символов
##### Обучение LSTM-модели языка символов
##### Настройка LSTM-модели языка символов
##### Итоги

## 15. Глубокое обучение на конфиденциальных данных: введение в федеративное обучение
##### Проблема конфиденциальности в глубоком обучении
##### Федеративное обучение
##### Обучаем выявлять спам
##### Сделаем модель федеративной
##### Взламываем федеративную модель
##### Безопасное агрегирование
##### Гомоморфное шифрование
##### Федеративное обучение с гомоморфным шифрованием
##### Итоги

## 16. Куда пойти дальше: краткий путеводитель
##### Поздравляю!
##### Шаг 1: начните изучать PyTorch
##### Шаг 2: начните изучать следующий курс по глубокому обучению
##### Шаг 3: купите учебник по математике глубокого обучения
##### Шаг 4: заведите блог и рассказывайте в нем о глубоком обучении
##### Шаг 5: Twitter
##### Шаг 6: напишите руководство на основе академической статьи
##### Шаг 7: получите доступ к GPU
##### Шаг 8: найдите оплачиваемую работу, связанную с глубоким обучением
##### Шаг 9: присоединитесь к открытому проекту
##### Шаг 10: ищите единомышленников .....
